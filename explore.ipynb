{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据形状: (10000, 300)\n",
      "类别分布:\n",
      " label\n",
      "5     0.4479\n",
      "10    0.1081\n",
      "6     0.0553\n",
      "8     0.0516\n",
      "12    0.0457\n",
      "24    0.0385\n",
      "17    0.0354\n",
      "26    0.0278\n",
      "21    0.0269\n",
      "14    0.0264\n",
      "4     0.0238\n",
      "25    0.0184\n",
      "19    0.0177\n",
      "20    0.0153\n",
      "27    0.0107\n",
      "7     0.0103\n",
      "11    0.0078\n",
      "3     0.0065\n",
      "13    0.0062\n",
      "18    0.0060\n",
      "23    0.0041\n",
      "15    0.0026\n",
      "9     0.0025\n",
      "0     0.0018\n",
      "2     0.0007\n",
      "22    0.0007\n",
      "1     0.0007\n",
      "16    0.0006\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, log_loss, f1_score, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 设置随机种子，确保可重复性\n",
    "np.random.seed(42)\n",
    "\n",
    "# 加载数据\n",
    "X = pd.read_csv(\"data/X_train.csv\")  # 假设已部分标准化\n",
    "y = pd.read_csv(\"data/y_train.csv\").squeeze()  # 返回 Series\n",
    "\n",
    "# 检查数据基本信息\n",
    "print(\"数据形状:\", X.shape)\n",
    "print(\"类别分布:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征均值（标准化后）:\n",
      " count    3.000000e+02\n",
      "mean    -4.011606e-19\n",
      "std      1.377425e-17\n",
      "min     -3.197442e-17\n",
      "25%     -1.110223e-17\n",
      "50%     -8.881784e-19\n",
      "75%      1.065814e-17\n",
      "max      3.108624e-17\n",
      "dtype: float64\n",
      "训练集特征标准差（标准化后）:\n",
      " count    3.000000e+02\n",
      "mean     1.000063e+00\n",
      "std      2.037097e-15\n",
      "min      1.000063e+00\n",
      "25%      1.000063e+00\n",
      "50%      1.000063e+00\n",
      "75%      1.000063e+00\n",
      "max      1.000063e+00\n",
      "dtype: float64\n",
      "PCA 降维后特征数量: 100\n",
      "PCA 解释方差比例: 0.8681524900473957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 标准化（确保均值为 0，标准差为 1）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 转换为 DataFrame（可选，便于后续检查）\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "\n",
    "# 检查标准化结果\n",
    "print(\"训练集特征均值（标准化后）:\\n\", X_train_scaled.mean().describe())\n",
    "print(\"训练集特征标准差（标准化后）:\\n\", X_train_scaled.std().describe())\n",
    "\n",
    "# PCA 降维（动态选择 n_components，保留 100维）\n",
    "pca = PCA(n_components=100, random_state=42)  \n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "# 检查 PCA 结果\n",
    "print(\"PCA 降维后特征数量:\", X_train_pca.shape[1])\n",
    "print(\"PCA 解释方差比例:\", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【标准化前】训练集特征均值:\n",
      " count    300.000000\n",
      "mean      -0.003894\n",
      "std        0.053986\n",
      "min       -0.128020\n",
      "25%       -0.042983\n",
      "50%       -0.001708\n",
      "75%        0.036195\n",
      "max        0.121386\n",
      "dtype: float64\n",
      "【标准化前】训练集特征标准差:\n",
      " count    300.000000\n",
      "mean       0.994337\n",
      "std        0.014133\n",
      "min        0.959733\n",
      "25%        0.986148\n",
      "50%        0.994049\n",
      "75%        1.004648\n",
      "max        1.033039\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 对比标准化前的统计信息\n",
    "print(\"【标准化前】训练集特征均值:\\n\", X_train.mean().describe())\n",
    "print(\"【标准化前】训练集特征标准差:\\n\", X_train.std().describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【标准化后】训练集特征均值:\n",
      " count    3.000000e+02\n",
      "mean    -4.011606e-19\n",
      "std      1.377425e-17\n",
      "min     -3.197442e-17\n",
      "25%     -1.110223e-17\n",
      "50%     -8.881784e-19\n",
      "75%      1.065814e-17\n",
      "max      3.108624e-17\n",
      "dtype: float64\n",
      "【标准化后】训练集特征标准差:\n",
      " count    3.000000e+02\n",
      "mean     1.000063e+00\n",
      "std      2.037097e-15\n",
      "min      1.000063e+00\n",
      "25%      1.000063e+00\n",
      "50%      1.000063e+00\n",
      "75%      1.000063e+00\n",
      "max      1.000063e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 转成 DataFrame，便于后续检查\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)\n",
    "\n",
    "# 对比标准化后的统计信息\n",
    "print(\"\\n【标准化后】训练集特征均值:\\n\", X_train_scaled.mean().describe())\n",
    "print(\"【标准化后】训练集特征标准差:\\n\", X_train_scaled.std().describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA 降维后特征数量: 100\n",
      "PCA 解释方差比例总和: 0.8682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# PCA 降维（保留100维）\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "# 检查 PCA 结果\n",
    "print(\"\\nPCA 降维后特征数量:\", X_train_pca.shape[1])\n",
    "print(\"PCA 解释方差比例总和:\", round(sum(pca.explained_variance_ratio_), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别权重: {np.int64(0): np.float64(20.408163265306122), np.int64(1): np.float64(47.61904761904762), np.int64(2): np.float64(47.61904761904762), np.int64(3): np.float64(5.4945054945054945), np.int64(4): np.float64(1.5037593984962405), np.int64(5): np.float64(0.07974163709580957), np.int64(6): np.float64(0.6464124111182935), np.int64(7): np.float64(3.484320557491289), np.int64(8): np.float64(0.6918021445866482), np.int64(9): np.float64(14.285714285714286), np.int64(10): np.float64(0.33030553261767137), np.int64(11): np.float64(4.608294930875576), np.int64(12): np.float64(0.78064012490242), np.int64(13): np.float64(5.714285714285714), np.int64(14): np.float64(1.3540961408259986), np.int64(15): np.float64(13.605442176870747), np.int64(16): np.float64(57.142857142857146), np.int64(17): np.float64(1.0095911155981827), np.int64(18): np.float64(5.9523809523809526), np.int64(19): np.float64(2.0120724346076457), np.int64(20): np.float64(2.34192037470726), np.int64(21): np.float64(1.3289036544850499), np.int64(22): np.float64(47.61904761904762), np.int64(23): np.float64(8.658008658008658), np.int64(24): np.float64(0.9276437847866419), np.int64(25): np.float64(1.9436345966958213), np.int64(26): np.float64(1.287001287001287), np.int64(27): np.float64(3.3222591362126246)}\n"
     ]
    }
   ],
   "source": [
    "# 计算类别权重\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# 为训练集和验证集生成样本权重\n",
    "sample_weight_train = np.array([weight_dict[label] for label in y_train])\n",
    "sample_weight_val = np.array([weight_dict[label] for label in y_val])\n",
    "\n",
    "print(\"类别权重:\", weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的 k_neighbors = 4\n",
      "SMOTE 后训练集类别分布（原始标准化特征）:\n",
      "label\n",
      "12    0.035714\n",
      "4     0.035714\n",
      "2     0.035714\n",
      "11    0.035714\n",
      "1     0.035714\n",
      "13    0.035714\n",
      "0     0.035714\n",
      "26    0.035714\n",
      "16    0.035714\n",
      "6     0.035714\n",
      "7     0.035714\n",
      "9     0.035714\n",
      "27    0.035714\n",
      "17    0.035714\n",
      "3     0.035714\n",
      "19    0.035714\n",
      "14    0.035714\n",
      "18    0.035714\n",
      "25    0.035714\n",
      "21    0.035714\n",
      "10    0.035714\n",
      "24    0.035714\n",
      "23    0.035714\n",
      "8     0.035714\n",
      "22    0.035714\n",
      "20    0.035714\n",
      "5     0.035714\n",
      "15    0.035714\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 安全地确定 SMOTE 的 k 值\n",
    "min_count = min(Counter(y_train).values())\n",
    "k = max(1, min(min_count - 1, 5))\n",
    "print(f\"使用的 k_neighbors = {k}\")\n",
    "\n",
    "# 初始化 SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=k)\n",
    "\n",
    "# SMOTE 1：对标准化原始特征进行采样\n",
    "X_train_smote_orig, y_train_smote_orig = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# SMOTE 2：对 PCA 特征进行采样\n",
    "X_train_smote_pca, y_train_smote_pca = smote.fit_resample(X_train_pca, y_train)\n",
    "\n",
    "print(\"SMOTE 后训练集类别分布（原始标准化特征）:\")\n",
    "print(pd.Series(y_train_smote_orig).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te, sw_train=None):\n",
    "    # 训练模型\n",
    "    if sw_train is not None:\n",
    "        model.fit(X_tr, y_tr, sample_weight=sw_train)\n",
    "    else:\n",
    "        model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # 预测\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_proba = model.predict_proba(X_te)\n",
    "    \n",
    "    # 返回评估结果\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"macro_f1\": f1_score(y_te, y_pred, average='macro'),\n",
    "        \"weighted_f1\": f1_score(y_te, y_pred, average='weighted'),\n",
    "        \"log_loss\": log_loss(y_te, y_proba),\n",
    "        \"accuracy\": accuracy_score(y_te, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_base = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "lr_cw = LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "rf_base = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf_cw = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)\n",
    "\n",
    "# XGBoost\n",
    "xgb_base = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# LR\n",
    "# 不加 PCA\n",
    "# 基础模型\n",
    "results.append(evaluate_model(\"Logistic (Base, No PCA)\", lr_base, X_train_scaled, y_train, X_val_scaled, y_val))\n",
    "# class_weight\n",
    "results.append(evaluate_model(\"Logistic (class_weight, No PCA)\", lr_cw, X_train_scaled, y_train, X_val_scaled, y_val))\n",
    "# sample_weight\n",
    "results.append(evaluate_model(\"Logistic (sample_weight, No PCA)\", lr_base, X_train_scaled, y_train, X_val_scaled, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "lr_smote = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "results.append(evaluate_model(\"Logistic (SMOTE, No PCA)\", lr_smote, X_train_smote_orig, y_train_smote_orig, X_val_scaled, y_val))\n",
    "\n",
    "# 加 PCA\n",
    "# 基础模型\n",
    "results.append(evaluate_model(\"Logistic (Base, PCA)\", lr_base, X_train_pca, y_train, X_val_pca, y_val))\n",
    "# class_weight\n",
    "results.append(evaluate_model(\"Logistic (class_weight, PCA)\", lr_cw, X_train_pca, y_train, X_val_pca, y_val))\n",
    "# sample_weight\n",
    "results.append(evaluate_model(\"Logistic (sample_weight, PCA)\", lr_base, X_train_pca, y_train, X_val_pca, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "lr_smote_pca = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "results.append(evaluate_model(\"Logistic (SMOTE, PCA)\", lr_smote_pca, X_train_smote_pca, y_train_smote_pca, X_val_pca, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "# 不加 PCA\n",
    "# 基础模型\n",
    "results.append(evaluate_model(\"RF (Base, No PCA)\", rf_base, X_train_scaled, y_train, X_val_scaled, y_val))\n",
    "# class_weight\n",
    "results.append(evaluate_model(\"RF (class_weight, No PCA)\", rf_cw, X_train_scaled, y_train, X_val_scaled, y_val))\n",
    "# sample_weight\n",
    "results.append(evaluate_model(\"RF (sample_weight, No PCA)\", rf_base, X_train_scaled, y_train, X_val_scaled, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "rf_smote = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "results.append(evaluate_model(\"RF (SMOTE, No PCA)\", rf_smote, X_train_smote_orig, y_train_smote_orig, X_val_scaled, y_val))\n",
    "\n",
    "# 加 PCA\n",
    "# 基础模型\n",
    "results.append(evaluate_model(\"RF (Base, PCA)\", rf_base, X_train_pca, y_train, X_val_pca, y_val))\n",
    "# class_weight\n",
    "results.append(evaluate_model(\"RF (class_weight, PCA)\", rf_cw, X_train_pca, y_train, X_val_pca, y_val))\n",
    "# sample_weight\n",
    "results.append(evaluate_model(\"RF (sample_weight, PCA)\", rf_base, X_train_pca, y_train, X_val_pca, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "rf_smote_pca = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "results.append(evaluate_model(\"RF (SMOTE, PCA)\", rf_smote_pca, X_train_smote_pca, y_train_smote_pca, X_val_pca, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# 不加 PCA\n",
    "# 基础模型\n",
    "results.append(evaluate_model(\"XGBoost (Base, No PCA)\", xgb_base, X_train_scaled, y_train, X_val_scaled, y_val))\n",
    "# sample_weight\n",
    "xgb_sw = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")\n",
    "results.append(evaluate_model(\"XGBoost (sample_weight, No PCA)\", xgb_sw, X_train_scaled, y_train, X_val_scaled, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "xgb_smote = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")\n",
    "results.append(evaluate_model(\"XGBoost (SMOTE, No PCA)\", xgb_smote, X_train_smote_orig, y_train_smote_orig, X_val_scaled, y_val))\n",
    "\n",
    "# 加 PCA\n",
    "# 基础模型\n",
    "xgb_base_pca = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")\n",
    "results.append(evaluate_model(\"XGBoost (Base, PCA)\", xgb_base_pca, X_train_pca, y_train, X_val_pca, y_val))\n",
    "# sample_weight\n",
    "xgb_sw_pca = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")\n",
    "results.append(evaluate_model(\"XGBoost (sample_weight, PCA)\", xgb_sw_pca, X_train_pca, y_train, X_val_pca, y_val, sample_weight_train))\n",
    "# SMOTE\n",
    "xgb_smote_pca = XGBClassifier(\n",
    "    n_estimators=200, max_depth=6, learning_rate=0.1, \n",
    "    objective='multi:softprob', num_class=len(np.unique(y)), \n",
    "    eval_metric='mlogloss', random_state=42\n",
    ")\n",
    "results.append(evaluate_model(\"XGBoost (SMOTE, PCA)\", xgb_smote_pca, X_train_smote_pca, y_train_smote_pca, X_val_pca, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型性能对比（按 macro_f1 排序）：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost (SMOTE, No PCA)</td>\n",
       "      <td>0.480869</td>\n",
       "      <td>0.749294</td>\n",
       "      <td>0.872681</td>\n",
       "      <td>0.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic (Base, PCA)</td>\n",
       "      <td>0.480402</td>\n",
       "      <td>0.764787</td>\n",
       "      <td>0.882960</td>\n",
       "      <td>0.7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost (sample_weight, PCA)</td>\n",
       "      <td>0.455843</td>\n",
       "      <td>0.736977</td>\n",
       "      <td>0.887129</td>\n",
       "      <td>0.7560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic (Base, No PCA)</td>\n",
       "      <td>0.453989</td>\n",
       "      <td>0.736295</td>\n",
       "      <td>1.302974</td>\n",
       "      <td>0.7450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost (sample_weight, No PCA)</td>\n",
       "      <td>0.444386</td>\n",
       "      <td>0.742683</td>\n",
       "      <td>0.834154</td>\n",
       "      <td>0.7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (SMOTE, PCA)</td>\n",
       "      <td>0.443818</td>\n",
       "      <td>0.735381</td>\n",
       "      <td>0.952801</td>\n",
       "      <td>0.7470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic (class_weight, No PCA)</td>\n",
       "      <td>0.440973</td>\n",
       "      <td>0.694061</td>\n",
       "      <td>1.538232</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic (sample_weight, No PCA)</td>\n",
       "      <td>0.440973</td>\n",
       "      <td>0.694061</td>\n",
       "      <td>1.538232</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic (SMOTE, No PCA)</td>\n",
       "      <td>0.432726</td>\n",
       "      <td>0.683916</td>\n",
       "      <td>2.550309</td>\n",
       "      <td>0.6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic (sample_weight, PCA)</td>\n",
       "      <td>0.432649</td>\n",
       "      <td>0.669488</td>\n",
       "      <td>1.361789</td>\n",
       "      <td>0.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic (class_weight, PCA)</td>\n",
       "      <td>0.432649</td>\n",
       "      <td>0.669488</td>\n",
       "      <td>1.361789</td>\n",
       "      <td>0.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF (SMOTE, No PCA)</td>\n",
       "      <td>0.431417</td>\n",
       "      <td>0.671045</td>\n",
       "      <td>1.640834</td>\n",
       "      <td>0.6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic (SMOTE, PCA)</td>\n",
       "      <td>0.417710</td>\n",
       "      <td>0.662905</td>\n",
       "      <td>1.912308</td>\n",
       "      <td>0.6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF (SMOTE, PCA)</td>\n",
       "      <td>0.403575</td>\n",
       "      <td>0.649726</td>\n",
       "      <td>1.784552</td>\n",
       "      <td>0.6270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost (Base, No PCA)</td>\n",
       "      <td>0.388942</td>\n",
       "      <td>0.728634</td>\n",
       "      <td>0.912060</td>\n",
       "      <td>0.7590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost (Base, PCA)</td>\n",
       "      <td>0.383907</td>\n",
       "      <td>0.721921</td>\n",
       "      <td>0.952249</td>\n",
       "      <td>0.7505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RF (class_weight, PCA)</td>\n",
       "      <td>0.369269</td>\n",
       "      <td>0.666030</td>\n",
       "      <td>1.882586</td>\n",
       "      <td>0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF (sample_weight, PCA)</td>\n",
       "      <td>0.369269</td>\n",
       "      <td>0.666030</td>\n",
       "      <td>1.882586</td>\n",
       "      <td>0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RF (class_weight, No PCA)</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>1.885588</td>\n",
       "      <td>0.6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF (sample_weight, No PCA)</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>1.885588</td>\n",
       "      <td>0.6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RF (Base, No PCA)</td>\n",
       "      <td>0.198989</td>\n",
       "      <td>0.605097</td>\n",
       "      <td>1.198808</td>\n",
       "      <td>0.6825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF (Base, PCA)</td>\n",
       "      <td>0.181977</td>\n",
       "      <td>0.574060</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model  macro_f1  weighted_f1  log_loss  \\\n",
       "0            XGBoost (SMOTE, No PCA)  0.480869     0.749294  0.872681   \n",
       "1               Logistic (Base, PCA)  0.480402     0.764787  0.882960   \n",
       "2       XGBoost (sample_weight, PCA)  0.455843     0.736977  0.887129   \n",
       "3            Logistic (Base, No PCA)  0.453989     0.736295  1.302974   \n",
       "4    XGBoost (sample_weight, No PCA)  0.444386     0.742683  0.834154   \n",
       "5               XGBoost (SMOTE, PCA)  0.443818     0.735381  0.952801   \n",
       "6    Logistic (class_weight, No PCA)  0.440973     0.694061  1.538232   \n",
       "7   Logistic (sample_weight, No PCA)  0.440973     0.694061  1.538232   \n",
       "8           Logistic (SMOTE, No PCA)  0.432726     0.683916  2.550309   \n",
       "9      Logistic (sample_weight, PCA)  0.432649     0.669488  1.361789   \n",
       "10      Logistic (class_weight, PCA)  0.432649     0.669488  1.361789   \n",
       "11                RF (SMOTE, No PCA)  0.431417     0.671045  1.640834   \n",
       "12             Logistic (SMOTE, PCA)  0.417710     0.662905  1.912308   \n",
       "13                   RF (SMOTE, PCA)  0.403575     0.649726  1.784552   \n",
       "14            XGBoost (Base, No PCA)  0.388942     0.728634  0.912060   \n",
       "15               XGBoost (Base, PCA)  0.383907     0.721921  0.952249   \n",
       "16            RF (class_weight, PCA)  0.369269     0.666030  1.882586   \n",
       "17           RF (sample_weight, PCA)  0.369269     0.666030  1.882586   \n",
       "18         RF (class_weight, No PCA)  0.350233     0.655033  1.885588   \n",
       "19        RF (sample_weight, No PCA)  0.350233     0.655033  1.885588   \n",
       "20                 RF (Base, No PCA)  0.198989     0.605097  1.198808   \n",
       "21                    RF (Base, PCA)  0.181977     0.574060  1.256836   \n",
       "\n",
       "    accuracy  \n",
       "0     0.7585  \n",
       "1     0.7780  \n",
       "2     0.7560  \n",
       "3     0.7450  \n",
       "4     0.7630  \n",
       "5     0.7470  \n",
       "6     0.6610  \n",
       "7     0.6610  \n",
       "8     0.6525  \n",
       "9     0.6240  \n",
       "10    0.6240  \n",
       "11    0.6515  \n",
       "12    0.6135  \n",
       "13    0.6270  \n",
       "14    0.7590  \n",
       "15    0.7505  \n",
       "16    0.6710  \n",
       "17    0.6710  \n",
       "18    0.6520  \n",
       "19    0.6520  \n",
       "20    0.6825  \n",
       "21    0.6610  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整理结果\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=\"macro_f1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 显示结果\n",
    "print(\"模型性能对比（按 macro_f1 排序）：\")\n",
    "results_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 模型结果对比\n",
    "\n",
    "| 排名 | 模型                                | Macro F1 | Weighted F1 | Accuracy |\n",
    "|------|-------------------------------------|----------|--------------|----------|\n",
    "| 1    | XGBoost (SMOTE, No PCA)             | **0.4809** | 0.7493       | 0.7585   |\n",
    "| 2    | Logistic (Base, PCA)                | **0.4804** | 0.7648       | 0.7780   |\n",
    "| 3    | XGBoost (sample_weight, PCA)        | 0.4558    | 0.7360       | 0.7560   |\n",
    "| 4    | Logistic (Base, No PCA)             | 0.4539    | 0.7363       | 0.7450   |\n",
    "| 5    | XGBoost (sample_weight, No PCA)     | 0.4444    | 0.7427       | 0.7630   |\n",
    "\n",
    "**XGBoost + SMOTE（不加 PCA）** 拿下了最高的 Macro F1，表现优秀。\n",
    "\n",
    "**Logistic Regression** 在**不使用类别平衡策略**时，基础表现已经很强，说明特征本身具备较好区分能力。\n",
    "\n",
    "加入 `sample_weight` 或 `class_weight` 虽然在一定程度上提升了表现，但整体效果仍不如 SMOTE 显著。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
